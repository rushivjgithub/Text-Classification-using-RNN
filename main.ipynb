{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nld7_dutY3SL"
   },
   "source": [
    "# Text Classification using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROfu6U2YZFT1"
   },
   "source": [
    "## Business Problem\n",
    "\n",
    "Spam and ham classification plays a crucial role in contemporary communication systems, especially in the context of electronic communication channels like emails and text messages. With the exponential growth of digital communication, the significance of accurate spam and ham classification has become increasingly important for several reasons:\n",
    "\n",
    "1. **User Experience:** Efficient spam filtering ensures a better user experience by preventing unwanted and irrelevant content from reaching users' inboxes. Users are less likely to be inundated with unsolicited messages, leading to a cleaner and more organized communication environment.\n",
    "\n",
    "2. **Productivity:** Spam filtering contributes to increased productivity as users spend less time sifting through irrelevant or potentially harmful messages. It allows individuals and organizations to focus on legitimate and valuable communication, improving overall workflow efficiency.\n",
    "\n",
    "3. **Security:** Many spam messages are associated with phishing attempts, scams, and malware distribution. Effective spam filtering acts as a frontline defense against cyber threats by identifying and isolating malicious content, thereby enhancing the security posture of individuals and organizations.\n",
    "\n",
    "4. **Resource Optimization:** By reducing the volume of spam that enters email servers and messaging platforms, resources such as storage, bandwidth, and processing power can be optimized. This is particularly crucial for large-scale email providers and enterprises dealing with vast amounts of communication data.\n",
    "\n",
    "5. **Brand Reputation:** For businesses and organizations, spam filtering is essential for maintaining a positive brand reputation. Preventing spam from reaching customers' inboxes ensures that legitimate messages are not overlooked or associated with undesirable content, preserving trust and credibility.\n",
    "\n",
    "6. **Regulatory Compliance:** Compliance with data protection and privacy regulations often requires organizations to implement measures to protect users from unwanted communication. Adequate spam and ham classification helps in meeting regulatory requirements and avoiding potential legal implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zN_pB39qbKye"
   },
   "source": [
    "## Data  \n",
    "**Context**  \n",
    "The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,572 messages, tagged acording being ham (legitimate) or spam.  \n",
    "\n",
    "**Acknowledgement**  \n",
    "The original dataset can be found [here](https://archive.ics.uci.edu/dataset/228/sms+spam+collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_GtJPzscUtb"
   },
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1703969314256,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "-dZkB7980Bp5",
    "outputId": "0fa4e0d1-bdfb-407a-9b9b-aac86fce9360"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, LSTM, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp=pd.read_csv(\"C:\\Dataset\\spam1.csv\" ,encoding ='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0esI69AVcca_"
   },
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1703969317297,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "GrAdOs7o0whD",
    "outputId": "5b08c788-1fc8-49f0-b416-bc0633b2121e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6771</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6772</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6773</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6776 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "6771  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "6772   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "6773   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "6774   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "6775   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "6771        NaN        NaN  \n",
       "6772        NaN        NaN  \n",
       "6773        NaN        NaN  \n",
       "6774        NaN        NaN  \n",
       "6775        NaN        NaN  \n",
       "\n",
       "[6776 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the file\n",
    "file_content = pd.read_csv(\"C:\\Dataset\\spam1.csv\" ,encoding ='latin-1')\n",
    "file_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6HCoETkbC1V"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1703969319661,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "kkqyvAT71Klx",
    "outputId": "54f8adb4-e87b-4445-9fd4-46b86d9fb063"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "6771    This is the 2nd time we have tried 2 contact u...\n",
       "6772                Will Ì_ b going to esplanade fr home?\n",
       "6773    Pity, * was in mood for that. So...any other s...\n",
       "6774    The guy did some bitching but I acted like i'd...\n",
       "6775                           Rofl. Its true to its name\n",
       "Name: v2, Length: 6776, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking only the email column\n",
    "file_content[\"v2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1703969321718,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "Yq4y8nKk1hbX",
    "outputId": "2a21e772-2d35-41e7-b35c-8840edb6e999"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go jurong point, crazy.. Available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say early hor... U c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6771</th>\n",
       "      <td>spam</td>\n",
       "      <td>This 2nd time tried 2 contact u. U å£750 Pound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6772</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6773</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * mood that. So...any suggestions?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy bitching I acted like i'd interested b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                              Email\n",
       "0       ham  Go jurong point, crazy.. Available bugis n gre...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3       ham          U dun say early hor... U c already say...\n",
       "4       ham          Nah I think goes usf, lives around though\n",
       "...     ...                                                ...\n",
       "6771   spam  This 2nd time tried 2 contact u. U å£750 Pound...\n",
       "6772    ham                 Will Ì_ b going esplanade fr home?\n",
       "6773    ham           Pity, * mood that. So...any suggestions?\n",
       "6774    ham  The guy bitching I acted like i'd interested b...\n",
       "6775    ham                                Rofl. Its true name\n",
       "\n",
       "[6776 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the stop words\n",
    "stop = stopwords.words(\"english\")\n",
    "file_content[\"v2\"] = file_content[\"v2\"].apply(\n",
    "    lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "# delete unwanted columns\n",
    "Email_Data = file_content[['v1', 'v2']]\n",
    "\n",
    "#rename column names\n",
    "Email_Data = Email_Data.rename(columns={\"v1\":\"Target\", \"v2\":\"Email\"})\n",
    "Email_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1703969321718,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "1fb_ZlpFWwZC",
    "outputId": "4d73ce60-c474-48bf-87f0-f68f4b78ff5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "ham     5854\n",
       "spam     922\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Email_Data.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1703969323030,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "HQkcVhN86a7z",
    "outputId": "84ad18e4-4c63-4e5e-93da-8bbb390d9e4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazy available bugis n great ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3                  u dun say early hor u c already say\n",
       "4             nah i think goes usf lives around though\n",
       "Name: Email, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete punctuations, convert text to lowercase, and remove double spaces\n",
    "\n",
    "Email_Data['Email'] = Email_Data['Email'].apply(\n",
    "    lambda x: re.sub('[!@#$:).;,?&]', '', x.lower()))\n",
    "Email_Data['Email'] = Email_Data['Email'].apply(\n",
    "    lambda x: re.sub(' +', ' ', x))\n",
    "Email_Data['Email'].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1703969323736,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "qa79t993LypI"
   },
   "outputs": [],
   "source": [
    "# Separating text(input) and target classes\n",
    "list_sentences_rawdata = Email_Data[\"Email\"].fillna(\"_na_\").values\n",
    "list_classes = [\"Target\"]\n",
    "target = Email_Data[list_classes].values\n",
    "To_Process = Email_Data[[\"Email\", \"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1703969324507,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "3moAssErOiCr",
    "outputId": "854dbf6d-d179-4252-8407-f214f12d0a34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ham'],\n",
       "       ['ham'],\n",
       "       ['spam'],\n",
       "       ...,\n",
       "       ['ham'],\n",
       "       ['ham'],\n",
       "       ['ham']], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1703969324509,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "svvJXlqwOkWj",
    "outputId": "3567fbc0-5a2b-4789-b4e6-e41b8f2a1d0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i think goes usf lives around though</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6771</th>\n",
       "      <td>this 2nd time tried 2 contact u u å£750 pound ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6772</th>\n",
       "      <td>will ì_ b going esplanade fr home</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6773</th>\n",
       "      <td>pity * mood that soany suggestions</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>the guy bitching i acted like i'd interested b...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>rofl its true name</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Target\n",
       "0     go jurong point crazy available bugis n great ...    ham\n",
       "1                               ok lar joking wif u oni    ham\n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...   spam\n",
       "3                   u dun say early hor u c already say    ham\n",
       "4              nah i think goes usf lives around though    ham\n",
       "...                                                 ...    ...\n",
       "6771  this 2nd time tried 2 contact u u å£750 pound ...   spam\n",
       "6772                  will ì_ b going esplanade fr home    ham\n",
       "6773                 pity * mood that soany suggestions    ham\n",
       "6774  the guy bitching i acted like i'd interested b...    ham\n",
       "6775                                 rofl its true name    ham\n",
       "\n",
       "[6776 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "To_Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1703969325079,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "NBx1dwWNPoyC",
    "outputId": "d9d17e07-e7e3-4bf7-e416-9055264b7130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7886 unique tokens.\n",
      "(4743, 300)\n",
      "(2033, 300)\n"
     ]
    }
   ],
   "source": [
    "# Preparing data for model building\n",
    "train, test = train_test_split(To_Process, test_size=0.3)\n",
    "\n",
    "# Defining the sequence lengths, max number of words and embedding dimensions\n",
    "# sequence length of each sentence. If more, truncate. If less, pad with zeros\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "\n",
    "# Top 20000 frequently occuring words\n",
    "MAX_NB_WORDS = 20000\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train.Email)\n",
    "train_sequences = tokenizer.texts_to_sequences(train.Email)\n",
    "test_sequences = tokenizer.texts_to_sequences(test.Email)\n",
    "\n",
    "# dictionary containing words and their index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# total words in the corpus\n",
    "print(\"Found %s unique tokens.\" % len(word_index))\n",
    "c\n",
    "# get only the top frequent words on train\n",
    "train_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# get only the top frequent word on text\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1703969326770,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "OMukipQRVejV",
    "outputId": "1e3e6743-4f38-4521-813c-c09a61be3aab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n",
      "(array([0, 1]), array([4080,  663], dtype=int64))\n",
      "(array([0, 1]), array([1774,  259], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "train_labels = train[\"Target\"]\n",
    "test_labels = test[\"Target\"]\n",
    "\n",
    "# Convert the character array to numeric array. Assigns levels to unique labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_labels)\n",
    "print(le.classes_)\n",
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1703969328556,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "RPqCRv3HXI46",
    "outputId": "5f4da81a-1b81-4a17-a766-027bd19b99d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (4743, 300)\n",
      "Shape of label tensor: (4743, 2)\n",
      "Shape of label tensor: (2033, 2)\n"
     ]
    }
   ],
   "source": [
    "# changing data types\n",
    "labels_train = to_categorical(np.asarray(train_labels))\n",
    "labels_test = to_categorical(np.asarray(test_labels))\n",
    "print('Shape of data tensor:', train_data.shape)\n",
    "print('Shape of label tensor:', labels_train.shape)\n",
    "print('Shape of label tensor:', labels_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1703969331158,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "dapN1wmKXkeg",
    "outputId": "05eaf83a-0443-491a-b480-2f51e75e54b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "print(MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a_F6gRrcvSl"
   },
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1703969333949,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "EZTGMYAk689m",
    "outputId": "6b0adb4e-0b16-481e-f4f7-3f9f44812c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Simple RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model building\n",
    "print(\"Training Simple RNN\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(SimpleRNN(2))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143871,
     "status": "ok",
     "timestamp": 1703969479570,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "-UtTX-G99QPJ",
    "outputId": "ac266c8d-ef5a-4e94-979f-210f6ceea257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 119ms/step - accuracy: 0.8370 - loss: 0.5784 - val_accuracy: 0.9326 - val_loss: 0.3989\n",
      "Epoch 2/5\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 110ms/step - accuracy: 0.9596 - loss: 0.3061 - val_accuracy: 0.9174 - val_loss: 0.3137\n",
      "Epoch 3/5\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 108ms/step - accuracy: 0.9852 - loss: 0.1870 - val_accuracy: 0.9188 - val_loss: 0.2746\n",
      "Epoch 4/5\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 112ms/step - accuracy: 0.9937 - loss: 0.1217 - val_accuracy: 0.9090 - val_loss: 0.2563\n",
      "Epoch 5/5\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 113ms/step - accuracy: 0.9953 - loss: 0.0856 - val_accuracy: 0.9061 - val_loss: 0.2446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a04bd6f8d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, labels_train, batch_size=16, epochs=5, validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdSLkjrmdC_F"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1643,
     "status": "ok",
     "timestamp": 1703969486131,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "nyUSZzBbem1F",
    "outputId": "0ec58ece-5181-4d3b-b579-1c05a62d239d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
      "Precision: 0.9091220879792187\n",
      "Recall: 0.9060501721593703\n",
      "F-score: 0.9074593157156039\n",
      "Support: None\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.94      0.95      1774\n",
      "        spam       0.62      0.67      0.64       259\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      2033\n",
      "   macro avg       0.79      0.80      0.80      2033\n",
      "weighted avg       0.91      0.91      0.91      2033\n",
      " samples avg       0.91      0.91      0.91      2033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define class names\n",
    "class_names = ['ham', 'spam']\n",
    "\n",
    "# Predictions\n",
    "predicted_Srnn = model.predict(test_data)\n",
    "\n",
    "# Converting probabilities to binary predictions\n",
    "binary_predictions = np.round(predicted_Srnn)\n",
    "\n",
    "# Calculating precision, recall, fscore, and support\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "                              labels_test,\n",
    "                              binary_predictions,\n",
    "                              average='weighted')\n",
    "\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F-score: {}'.format(fscore))\n",
    "print('Support: {}'.format(support))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# Classification Report with class names\n",
    "report = classification_report(labels_test, binary_predictions, target_names=class_names)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siMM56zYdKdA"
   },
   "source": [
    "# Deploying the Model on Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 3071,
     "status": "ok",
     "timestamp": 1703969556018,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "3R7YfaQiEkPv"
   },
   "outputs": [],
   "source": [
    "model.save('model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1703969576486,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "DLoTRK1ZNv8e"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the tokenizer to a file\n",
    "with open('tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    pickle.dump(tokenizer, tokenizer_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "L2onlWtmO41K"
   },
   "outputs": [],
   "source": [
    "# !pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1703969595661,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "6l8nSHMyPyLK"
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "executionInfo": {
     "elapsed": 8919,
     "status": "ok",
     "timestamp": 1703969622832,
     "user": {
      "displayName": "Ajay Panigrahi",
      "userId": "13412841063262065312"
     },
     "user_tz": -330
    },
    "id": "TS-KHgJFGnaW",
    "outputId": "a10de3ac-2bb9-4509-bf1a-861975be1449"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n"
     ]
    }
   ],
   "source": [
    "# Loading the trained model\n",
    "model = load_model('model.keras')\n",
    "# Loading the tokenizer from the file\n",
    "with open('tokenizer.pkl', 'rb') as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "def preprocess_input_sequence(input_sequence):\n",
    "    # preprocessing the input text.\n",
    "    stop = stopwords.words(\"english\")\n",
    "    input_sequence = \" \".join(x for x in input_sequence.split() if x not in stop)\n",
    "    input_sequence = re.sub('[!@#$:).;,?&]', '', input_sequence.lower())\n",
    "    input_sequence = re.sub(' +', ' ', input_sequence)\n",
    "    tokenized_sequence = tokenizer.texts_to_sequences([input_sequence])\n",
    "    processed_input_sequence = pad_sequences(tokenized_sequence,\n",
    "                                    maxlen=300)[0]\n",
    "    return processed_input_sequence\n",
    "\n",
    "def predict_sequence(input_sequence):\n",
    "    # Preprocess the input_sequence\n",
    "    processed_input = preprocess_input_sequence(input_sequence)\n",
    "\n",
    "    # Model prediction\n",
    "    prediction = model.predict(np.array([processed_input]))\n",
    "\n",
    "    # Converting probability to class (assuming binary classification)\n",
    "    predicted_class = int(np.round(prediction.flatten()[0]))\n",
    "\n",
    "    # Mapping class to 'ham' or 'spam'\n",
    "    result = 'ham' if predicted_class == 0 else 'spam'\n",
    "\n",
    "    return result\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_sequence,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",  # Output as text for displaying 'ham' or 'spam'\n",
    "    live=True\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P_LU7yydQPu"
   },
   "source": [
    "# End of the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZkYCfbTsK4Az248SYPuF5",
   "mount_file_id": "14UikMnuwz4M-snrH04oyD-HsLaNuyhiS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
